{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11191f18-75ec-4d6b-bba9-1abc9446766a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imutils\n",
    "!pip install efficientnet\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "import itertools\n",
    "import imutils\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "import matplotlib as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from efficientnet.tfkeras import EfficientNetB0\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "img_dir = 'C:\\\\Users\\\\Mukesh\\\\Downloads\\\\archive (5)\\\\gaussian_filtered_images'\n",
    "image_dir = Path(img_dir)\n",
    "filepaths = list(image_dir.glob(r'**/*.png'))\n",
    "\n",
    "labels = []\n",
    "for filepath in filepaths:\n",
    "    label = os.path.split(os.path.split(filepath)[0])[1]\n",
    "    labels.append(label)\n",
    "\n",
    "filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "labels = pd.Series(labels, name='Label')\n",
    "\n",
    "\n",
    "df = pd.concat([filepaths, labels], axis=1)\n",
    "\n",
    "df = df.sample(frac=1).reset_index(drop = True)\n",
    "\n",
    "df.head(4)\n",
    "df['Label'].value_counts()\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "Class_series = pd.Series(df['Label'])\n",
    "lis = [\"No_DR\", \"Mild\", \"Moderate\", \"Severe\", \"Proliferate_DR\"]\n",
    "\n",
    "DR_or_not = Class_series.value_counts().tolist()\n",
    "\n",
    "data = {'Severity': lis, 'Count': DR_or_not}\n",
    "df_plot = pd.DataFrame(data)\n",
    "\n",
    "fig = px.bar(df_plot, x='Count', y='Severity', orientation='h',\n",
    "             color='Severity', color_discrete_sequence=[\"skyblue\", \"black\", \"pink\", \"purple\", \"blue\"],\n",
    "             title='Percentage among the different Severities of DR')\n",
    "fig.update_layout(yaxis={'categoryorder': 'total ascending'})  \n",
    "fig.show()\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelEncoder = LabelEncoder()\n",
    "labelEncoder.fit(df['Label'])\n",
    "df['Label']=labelEncoder.transform(df['Label'])\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "n_samples = 400\n",
    "label_counts = df['Label'].value_counts()\n",
    "dfs_by_label_resampled = {}\n",
    "\n",
    "# Iterate through each label\n",
    "for label in range(5):    \n",
    "    # Check if there are enough samples for resampling\n",
    "    if label_counts[label] < n_samples:\n",
    "        # If there are not enough samples, duplicate the existing ones to reach 400\n",
    "        df_label_resampled = pd.concat([df[df['Label'] == label]] * ((n_samples + label_counts[label] - 1) // label_counts[label]))\n",
    "        df_label_resampled = df_label_resampled.sample(n_samples, replace=True, random_state=42)\n",
    "    else:\n",
    "        # If there are enough samples, resample to get exactly 400\n",
    "        df_label_resampled = resample(df[df['Label'] == label], n_samples=n_samples, replace=True, random_state=42)\n",
    "    \n",
    "    # Append the resampled DataFrame to the dictionary\n",
    "    dfs_by_label_resampled[label] = df_label_resampled\n",
    "\n",
    "# Concatenate the resampled DataFrames\n",
    "balanced_df = pd.concat(dfs_by_label_resampled.values())\n",
    "\n",
    "# Shuffle the rows\n",
    "balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "balanced_df['Label'].value_counts()\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "Class_series = pd.Series(balanced_df['Label'])\n",
    "lis = [\"No_DR\", \"Mild\", \"Moderate\", \"Severe\", \"Proliferate_DR\"]\n",
    "\n",
    "DR_or_not = Class_series.value_counts().tolist()\n",
    "\n",
    "data = {'Severity': lis, 'Count': DR_or_not}\n",
    "df_plot = pd.DataFrame(data)\n",
    "\n",
    "fig = px.bar(df_plot, x='Count', y='Severity', orientation='h',\n",
    "             color='Severity', color_discrete_sequence=[\"skyblue\", \"black\", \"pink\", \"purple\", \"blue\"],\n",
    "             title='Percentage among the different Severities of DR')\n",
    "fig.update_layout(yaxis={'categoryorder': 'total ascending'})  \n",
    "fig.show()\n",
    "\n",
    "import glob\n",
    "\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "directory = '/kaggle/input/diabetic-retinopathy-224x224-gaussian-filtered/gaussian_filtered_images/gaussian_filtered_images/'\n",
    "\n",
    "# Create a pattern to access all PNG files in the directory\n",
    "pattern = os.path.join(directory, '*', '*.png')\n",
    "\n",
    "# Use glob to get all file paths matching the pattern\n",
    "image_paths = glob.glob(pattern)\n",
    "\n",
    "size = (224, 224)\n",
    "\n",
    "\n",
    "def load_image_and_resize(filepath):\n",
    "        img = Image.open(filepath)\n",
    "        img = img.resize(size)\n",
    "        img = np.asarray(img)\n",
    "        return img\n",
    "\n",
    "balanced_df['image'] = balanced_df['Filepath'].map(lambda x: load_image_and_resize(x))\n",
    "\n",
    "balanced_df['image']\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "sampled_images = balanced_df['image'].sample(6, random_state=42)\n",
    "size = (224, 224)\n",
    "sampled_images = [Image.fromarray(img).resize(size) for img in sampled_images]\n",
    "\n",
    "sampled_images = [np.array(img) for img in sampled_images]\n",
    "\n",
    "fig = make_subplots(rows=2, cols=3, subplot_titles=(\"Image 1\", \"Image 2\", \"Image 3\", \"Image 4\", \"Image 5\", \"Image 6\"))\n",
    "\n",
    "for i, img in enumerate(sampled_images, start=1):\n",
    "    fig.add_trace(go.Image(z=img), row=(i-1) // 3 + 1, col=(i-1) % 3 + 1)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Sample Images\",\n",
    "    width=800,\n",
    "    height=600,\n",
    "    margin=dict(l=20, r=20, t=60, b=20),\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "x=np.asarray(balanced_df['image'].to_list())\n",
    "x=x/255\n",
    "y=balanced_df['Label']\n",
    "y=to_categorical(y,num_classes=5)\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.2,random_state=42,shuffle=True)\n",
    "\n",
    "\n",
    "x\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "es = EarlyStopping(monitor='val_accuracy', min_delta = 0.005, patience=10, verbose=1, mode='auto')\n",
    "vgg = DenseNet121(input_shape=(224,224,3),weights='imagenet',include_top=False)\n",
    "vgg.trainable = False\n",
    "x = Flatten()(vgg.output)\n",
    "x = layers.Dense(256,activation='relu')(x)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "\n",
    "prediction = Dense(5,activation='softmax')(x)\n",
    "model = Model(inputs=vgg.input, outputs=prediction)\n",
    "model.compile(Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train ,\n",
    "                    y_train ,\n",
    "                    epochs=70 ,\n",
    "                    batch_size=8,\n",
    "                    validation_data=(x_test , y_test) ,\n",
    "                    callbacks=es\n",
    "                    )\n",
    "\n",
    "model_save_path = r\"C:\\Users\\Mukesh\\AppData\\diabeticfolder\\newmodel.h5\"\n",
    "model.save(model_save_path)\n",
    "print(f'Model saved to {model_save_path}')\n",
    "\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "# Print the loss and accuracy\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "tr_acc = history.history['accuracy']\n",
    "tr_loss = history.history['loss']\n",
    "val_acc = history.history['val_accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = [i+1 for i in range(len(tr_acc))]\n",
    "\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, tr_loss, 'r', label='Train Loss')\n",
    "plt.plot(epochs, val_loss, 'g', label='Valid Loss')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, tr_acc, 'r', label='Train Accuracy')\n",
    "plt.plot(epochs, val_acc, 'g', label='Valid Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Path where your model is saved\n",
    "model_path = r\"C:\\Users\\Mukesh\\AppData\\diabeticfolder\\newmodel.h5\"\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model(model_path)\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Path to your single image file\n",
    "img_path ='C:\\\\Users\\\\Mukesh\\\\Downloads\\\\archive (5)\\\\gaussian_filtered_images\\\\gaussian_filtered_images\\\\Proliferate_DR\\\\f2d2a0c92034.png'\n",
    "# Load and preprocess the image\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)  # Expand dimensions to create batch of size 1\n",
    "img_array /= 255.  # Normalize pixel values to [0, 1]\n",
    "\n",
    "# Optionally, you may need to apply additional preprocessing like mean subtraction or scaling\n",
    "# based on how the model was trained.\n",
    "\n",
    "# Predict the class probabilities\n",
    "predictions = model.predict(img_array)\n",
    "predicted_class_index = np.argmax(predictions, axis=1)[0]\n",
    "\n",
    "# Print the predicted class index (adjust as per your specific output)\n",
    "print(f'Predicted class index: {predicted_class_index}')\n",
    "\n",
    "# Optionally, if you have class labels, you can map the index to a label\n",
    "class_labels = ['Mild', 'Moderate', 'No_DR', 'Proliferate_DR', 'Severe']  # Replace with your actual class labels\n",
    "predicted_class_label = class_labels[predicted_class_index]\n",
    "\n",
    "print(f'Predicted class label: {predicted_class_label}')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
